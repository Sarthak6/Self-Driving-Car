{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional and Max Pooling Layers\n",
    "\n",
    "In order to get a better understanding of convolutional and max pooling layers, in this homework you will implement these two layers from scratch without PyTorch! Fill out the two python functions below and then run the `assert` statements in order to check that your code works :)\n",
    "\n",
    "Homework idea based off of assignment 2 from CS231N\n",
    "\n",
    "In this homework, you are only allowed to use the `numpy` package. I think this homework is fairly hard so please feel free to discuss with classmates on piazza. However, please post at most pseudocode for a subproblem and please do not post an answer.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ConvURL](https://raw.githubusercontent.com/iamaaditya/iamaaditya.github.io/master/images/conv_arithmetic/full_padding_no_strides_transposed.gif \"conv\")\n",
    "\n",
    "Recall the convolution layer. In this gif, we slide a 3 x 3 (dark blue) filter along the input image (light blue) in order to produce the (green) output image. There is no padding, and the stride is 1. To produce a green value, we dot a portion of the input image with the filter weights and add the bias ($Wx + b$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Convolutional Layer\n",
    "\n",
    "Implement `conv_forward_naive`, which takes in the input data, the weight matrix, the bias vector, and parameters about this convolutional layer.\n",
    "\n",
    "Hint: It may be a good idea to extract out N, C, H, W, F, etc. into variables for easier use.\n",
    "\n",
    "Hint2: How many `for` loops do you need?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_forward_naive(x, w, b, conv_param):\n",
    "    \"\"\"\n",
    "    A naive implementation of the forward pass for a convolutional layer.\n",
    "\n",
    "    The input consists of N data points, each with C channels, height H and\n",
    "    width W. We convolve each input with F different filters, where each filter\n",
    "    spans all C channels and has height HH and width WW.\n",
    "\n",
    "    Input:\n",
    "    - x: Input data of shape (N, C, H, W)\n",
    "    - w: Filter weights of shape (F, C, HH, WW)\n",
    "    - b: Biases, of shape (F,)\n",
    "    - conv_param: A dictionary with the following keys:\n",
    "      - 'stride': The number of pixels between adjacent receptive fields in the\n",
    "        horizontal and vertical directions.\n",
    "      - 'pad': The number of pixels that will be used to zero-pad the input.\n",
    "\n",
    "    Returns:\n",
    "    - out: Output data, of shape (N, F, H', W') where H' and W' are given by\n",
    "      H' = 1 + (H + 2 * pad - HH) / stride\n",
    "      W' = 1 + (W + 2 * pad - WW) / stride\n",
    "    \"\"\"\n",
    "    out = None\n",
    "    \n",
    "    stride = conv_param['stride']\n",
    "    padding = conv_param['pad']\n",
    "\n",
    "    n = x.shape[0]\n",
    "    c = x.shape[1]\n",
    "    h = x.shape[2]\n",
    "    width = x.shape[3]\n",
    "    \n",
    "    f = w.shape[0]\n",
    "    hh = w.shape[2]\n",
    "    ww = w.shape[3]\n",
    "\n",
    "    h_prime = int(1 + (h + 2 * padding - hh) / stride)\n",
    "    w_prime = int(1 + (width + 2 * padding - ww) / stride)\n",
    "\n",
    "    npad = ((0, 0), (0, 0), (padding, padding), (padding, padding))\n",
    "    x_pad = np.pad(x, pad_width=npad, mode='constant', constant_values=0)\n",
    "\n",
    "    out = np.zeros((n, f, h_prime, w_prime))\n",
    "    n_pad, c_pad, h_pad, w_pad = x_pad.shape\n",
    "   \n",
    "\n",
    "    ###########################################################################\n",
    "    # TODO: Implement the convolutional forward pass.                         #\n",
    "    # Hint: you can use the function np.pad for padding. We did this for you. #\n",
    "    # We also defined all the salient variables. The remaining part of this   #\n",
    "    # problem is creating the for loops and stitching the variables together. #\n",
    "    # Start by making sure you understand every portion of the above code.    #\n",
    "    # Hint2: Add the appropriate bias to each term in each convolution        #\n",
    "    ###########################################################################\n",
    "    \n",
    "    for N in range(n):\n",
    "        for F in range(f):\n",
    "            for i in range(0, h_pad - (hh - 1), stride):\n",
    "                for j in range(0, w_pad - (ww - 1), stride):\n",
    "                    image_to_be_weighted = x_pad[N, :, i:i+hh, j:j+ww]\n",
    "                    weights = w[F,...]\n",
    "                    product = np.sum(np.multiply(weights,image_to_be_weighted))\n",
    "                    row_block = int(i/stride)\n",
    "                    col_block = int(j/stride)\n",
    "                    out[N, F, row_block, col_block] = product + b[F]\n",
    "    print(\"out is \", out)\n",
    "\n",
    "\n",
    "    \n",
    "    ###########################################################################\n",
    "    #                             END OF YOUR CODE                            #\n",
    "    ###########################################################################\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Max Pooling Layer\n",
    "\n",
    "Implement this max pooling layer python function.\n",
    "\n",
    "Hint: This should be pretty similar to the convolution layer above.\n",
    "\n",
    "Hint2: It will be useful to calculate what the expected output dimensions will be. If you need help with this, feel free to chat a friend in the DeCal or a staff member."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pool_forward_naive(x, pool_param):\n",
    "    \"\"\"\n",
    "    A naive implementation of the forward pass for a max pooling layer.\n",
    "\n",
    "    Inputs:\n",
    "    - x: Input data, of shape (N, C, H, W)\n",
    "    - pool_param: dictionary with the following keys:\n",
    "      - 'pool_height': The height of each pooling region\n",
    "      - 'pool_width': The width of each pooling region\n",
    "      - 'stride': The distance between adjacent pooling regions\n",
    "\n",
    "    Returns:\n",
    "    - out: Output data\n",
    "    \"\"\"\n",
    "    out = None\n",
    "    ###########################################################################\n",
    "    # TODO: Implement the max pooling forward pass                            #\n",
    "    ###########################################################################\n",
    "   \n",
    "    height_pool = pool_param['pool_height']\n",
    "    width_pool = pool_param['pool_width']\n",
    "    stride = pool_param['stride']\n",
    "    n, c, h, w = x.shape \n",
    "    h1 = (h - height_pool) // stride + 1\n",
    "    w1 = (w - width_pool) // stride + 1\n",
    "    out = np.zeros((n, c, h1, w1))\n",
    "    for i in range(n):\n",
    "        for j in range(c):\n",
    "            for k in range(h1):\n",
    "                for l in range(w1):\n",
    "                    out[i,j,k,l] = np.max(x[i, j, k * stride:k * stride + height_pool, 1 * stride:1 * stride + width_pool])\n",
    "\n",
    "    ###########################################################################\n",
    "    #                             END OF YOUR CODE                            #\n",
    "    ###########################################################################\n",
    "    print(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Check your answers!\n",
    "\n",
    "If your code passes these assert statements, you should be good to go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out is  [[[[ 3.13783023 -3.39967189 -0.67034629  0.75443863 -7.34305417]\n",
      "   [-5.32751231  2.39404469 -7.53964901 -4.92723594  3.18673458]\n",
      "   [-1.71460357 -4.2126656  -8.11099708  3.06248213  6.33894349]\n",
      "   [-3.22003339  4.80549383 -6.24694429 -2.37856105 -1.72720915]\n",
      "   [ 3.27438643 -1.40836569 -1.82490217  8.86919592  0.77468496]]\n",
      "\n",
      "  [[-2.61841618 -6.49573417  6.75564931  0.59184847 -3.98443104]\n",
      "   [ 3.32434937 -0.33254641 -3.56840551  2.48632324  1.29550344]\n",
      "   [-0.93731549  0.93942528  4.27588487  4.99003361 -3.46922113]\n",
      "   [ 3.27477707 15.50203272 12.28841061  5.70073028 -2.73797865]\n",
      "   [ 0.63882942 -3.9097889  -6.50030743 -2.3884948  -1.05677199]]]]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-6483db9a0957>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m    \u001b[0;34m[\u001b[0m \u001b[0;36m6.75564931\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m3.56840551\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m4.27588487\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12.28841061\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m6.50030743\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m    \u001b[0;34m[\u001b[0m \u001b[0;36m0.59184847\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m2.48632324\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m4.99003361\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m5.70073028\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2.3884948\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m    [-3.98443104,  1.29550344, -3.46922113, -2.73797865, -1.05677199]]]]))\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### TESTING OF CONV LAYER\n",
    "\n",
    "np.random.seed(42)\n",
    "x = np.random.normal(size=[1, 3, 11, 11])\n",
    "w = np.random.normal(size=[2, 3, 5, 5])\n",
    "b = np.random.normal(size=[2])\n",
    "conv_param = {'stride': 3, 'pad': 3}\n",
    "result = conv_forward_naive(x, w, b, conv_param)\n",
    "assert np.allclose(result, np.array([[[[ 3.13783023, -5.32751231, -1.71460357, -3.22003339,  3.27438643],\n",
    "   [-3.39967189,  2.39404469, -4.2126656,   4.80549383, -1.40836569],\n",
    "   [-0.67034629, -7.53964901, -8.11099708, -6.24694429, -1.82490217],\n",
    "   [ 0.75443863, -4.92723594,  3.06248213, -2.37856105,  8.86919592],\n",
    "   [-7.34305417,  3.18673458,  6.33894349, -1.72720915,  0.77468496]],\n",
    "\n",
    "  [[-2.61841618,  3.32434937, -0.93731549,  3.27477707,  0.63882942],\n",
    "   [-6.49573417, -0.33254641,  0.93942528, 15.50203272, -3.9097889 ],\n",
    "   [ 6.75564931, -3.56840551,  4.27588487, 12.28841061, -6.50030743],\n",
    "   [ 0.59184847,  2.48632324,  4.99003361,  5.70073028, -2.3884948 ],\n",
    "   [-3.98443104,  1.29550344, -3.46922113, -2.73797865, -1.05677199]]]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[2.24808957 2.24808957]\n",
      "   [2.24808957 2.24808957]]\n",
      "\n",
      "  [[1.81659525 1.81659525]\n",
      "   [1.76020474 1.76020474]]\n",
      "\n",
      "  [[1.62741182 1.62741182]\n",
      "   [1.67882964 1.67882964]]]]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-c2b889fe5509>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         [[ 2.99363398,  1.62741182],\n\u001b[0;32m---> 14\u001b[0;31m          [ 1.67882964,  1.67882964]]]]) )\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### TESTING OF MAX POOL LAYER\n",
    "np.random.seed(45)\n",
    "x = np.random.normal(size=(1, 3, 8, 8))\n",
    "pool_param = {'pool_height': 5, 'pool_width': 5, 'stride': 3}\n",
    "result = max_pool_forward_naive(x, pool_param)\n",
    "\n",
    "assert np.allclose(result, np.array([[[[ 2.24808957,  2.24808957],\n",
    "         [ 2.24808957,  2.24808957]],\n",
    "\n",
    "        [[ 1.21650079,  1.81659525],\n",
    "         [ 2.44659327,  1.76020474]],\n",
    "\n",
    "        [[ 2.99363398,  1.62741182],\n",
    "         [ 1.67882964,  1.67882964]]]]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
